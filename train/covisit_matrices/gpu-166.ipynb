{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a450860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import cudf, glob, gc, pickle\n",
    "\n",
    "VER = 166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f71e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('../../data/train_data/train_parquet/*')\n",
    "len( files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a767c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files += glob.glob('../../data/train_data/test_parquet/*')\n",
    "len( files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eadb35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raid/Kaggle/otto/valid/train_parquet/099.parquet',\n",
       " '/raid/Kaggle/otto/valid/train_parquet/047.parquet',\n",
       " '/raid/Kaggle/otto/valid/train_parquet/043.parquet',\n",
       " '/raid/Kaggle/otto/valid/train_parquet/086.parquet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a4ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type_weight = {0:0, 1:1, 2:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49cd3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MN = 1661119200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be254ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### PART 1\n",
      "Processing 20 files...\n",
      "0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , \n",
      "Processing 20 files...\n",
      "20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , \n",
      "Processing 20 files...\n",
      "40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , 50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , \n",
      "Processing 20 files...\n",
      "60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , 75 , 76 , 77 , 78 , 79 , \n",
      "Processing 20 files...\n",
      "80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , \n",
      "Processing 20 files...\n",
      "100 , 101 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , \n",
      "CPU times: user 1min 34s, sys: 42.1 s, total: 2min 16s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PIECES = 1\n",
    "SIZE = 1.86e6/PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(PIECES):\n",
    "    print()\n",
    "    print('### PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for a,b in [(0,20),(20,40),(40,60),(60,80),(80,100),(100,120)]:\n",
    "        print(f'Processing {b-a} files...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b):\n",
    "            # READ FILE\n",
    "            df = cudf.read_parquet(files[k])\n",
    "            \n",
    "            df['x'] = df.groupby('session').aid.transform('count')\n",
    "            if a>=100:\n",
    "                df = df.loc[df.x>3]\n",
    "            else:\n",
    "                df = df.loc[df.x>6]\n",
    "            df = df.drop('x',axis=1)\n",
    "            \n",
    "            #df = df.loc[df.ts>1662328791 - 60*60*24*28]\n",
    "            #df = df.loc[( df.ts >= MN + 60*60*24*DAY )] # START ON DAY OF WEEK \n",
    "            #if len(df)==0: continue\n",
    "                \n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "\n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df.loc[df['type'].isin([1,2])], on='session')\n",
    "            #df = df.loc[ ((df.ts_y - df.ts_x)> 0) ] #& ( df.ts_x < MN + 60*60*24*(DAY+1) ) ] \n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','ts_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            w = (1/2)**((df.ts_y - df.ts_x).abs()/60/60) # 6 HOUR HALF LIFE\n",
    "            df['wgt'] = w #df.type_y.map(type_weight)*w\n",
    "            \n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        print()\n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<40].drop('n',axis=1)\n",
    "    # SAVE PART TO DISK\n",
    "    df = tmp.to_pandas().groupby('aid_x').aid_y.apply(list)\n",
    "    with open(f'../../data/covisit_matrices/top_40_aids_v{VER}_{PART}.pkl', 'wb') as f:\n",
    "        pickle.dump(df.to_dict(), f)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
