{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a450860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import cudf, glob, gc, pickle\n",
    "\n",
    "VER = 801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f71e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('../../data/infer_data/*_parquet/*')\n",
    "len( files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eadb35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raid/Kaggle/otto/parquet/test_parquet/001300000_001400000.parquet',\n",
       " '/raid/Kaggle/otto/parquet/test_parquet/000800000_000900000.parquet',\n",
       " '/raid/Kaggle/otto/parquet/test_parquet/001500000_001600000.parquet',\n",
       " '/raid/Kaggle/otto/parquet/test_parquet/000000000_000100000.parquet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a4ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_weight = {0:1, 1:1, 2:1}\n",
    "type_labels = {'clicks':0, 'carts':1, 'orders':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83770d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(f):\n",
    "    df = cudf.read_parquet(f)\n",
    "    #df['d'] = cudf.to_datetime(df.ts*1e9).dt.day.astype('int8')\n",
    "    df.ts = (df.ts//1000).astype('int32')\n",
    "    df['type'] = df['type'].map(type_labels).astype('int8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be254ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### PART 1\n",
      "Processing 25 files...\n",
      "0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 , 18 , 19 , 20 , 21 , 22 , 23 , 24 , \n",
      "Processing 25 files...\n",
      "25 , 26 , 27 , 28 , 29 , 30 , 31 , 32 , 33 , 34 , 35 , 36 , 37 , 38 , 39 , 40 , 41 , 42 , 43 , 44 , 45 , 46 , 47 , 48 , 49 , \n",
      "Processing 25 files...\n",
      "50 , 51 , 52 , 53 , 54 , 55 , 56 , 57 , 58 , 59 , 60 , 61 , 62 , 63 , 64 , 65 , 66 , 67 , 68 , 69 , 70 , 71 , 72 , 73 , 74 , \n",
      "Processing 25 files...\n",
      "75 , 76 , 77 , 78 , 79 , 80 , 81 , 82 , 83 , 84 , 85 , 86 , 87 , 88 , 89 , 90 , 91 , 92 , 93 , 94 , 95 , 96 , 97 , 98 , 99 , \n",
      "Processing 25 files...\n",
      "100 , 101 , 102 , 103 , 104 , 105 , 106 , 107 , 108 , 109 , 110 , 111 , 112 , 113 , 114 , 115 , 116 , 117 , 118 , 119 , 120 , 121 , 122 , 123 , 124 , \n",
      "Processing 21 files...\n",
      "125 , 126 , 127 , 128 , 129 , 130 , 131 , 132 , 133 , 134 , 135 , 136 , 137 , 138 , 139 , 140 , 141 , 142 , 143 , 144 , 145 , \n",
      "CPU times: user 31.2 s, sys: 12.5 s, total: 43.7 s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PIECES = 1\n",
    "SIZE = 1.86e6/PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(PIECES):\n",
    "    print()\n",
    "    print('### PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for a,b in [(0,25),(25,50),(50,75),(75,100),(100,125),(125,146)]:\n",
    "        print(f'Processing {b-a} files...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        READ_CT = 1\n",
    "        for k in range(a,b,READ_CT):\n",
    "            # READ FILE\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1,READ_CT): \n",
    "                if k+i<b: df.append( read_file(files[k+i]) )\n",
    "            df = cudf.concat(df,ignore_index=True,axis=0)\n",
    "            \n",
    "            # NEW USERS IN LAST 2 WEEKS\n",
    "            df['mn'] = df.groupby('session').ts.transform('min')\n",
    "            df = df.loc[df.mn > 1662328791 - 60*60*24*14] \n",
    "            df = df.drop('mn',axis=1)\n",
    "            #print(files[k], df.shape )\n",
    "            \n",
    "            df = df.sort_values(['session','ts'],ascending=[True,True])\n",
    "            #df['k'] = np.arange(len(df))\n",
    "            \n",
    "            # USE TAIL OF SESSION\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            #df = df.loc[df.n<100].drop('n',axis=1)\n",
    "            \n",
    "            # CREATE PAIRS\n",
    "            #df = df.loc[df.n==0].merge(df.drop_duplicates(['session','aid','type']),on=['session'])\n",
    "            df = df.loc[df.n==0].merge(df, on=['session'])\n",
    "            df = df.loc[df.aid_x != df.aid_y]\n",
    "\n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            #df = df.sort_values('ts_x',ascending=False)\n",
    "            \n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df.sort_values(['session','ts_y'],ascending=[True,True])\n",
    "            df = df[['session', 'aid_x', 'aid_y','ts_x','ts_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y','type_y'])\n",
    "            \n",
    "            w = (1/2)**( (df.ts_x - df.ts_y).abs() /60/60)\n",
    "            df['wgt'] = w #df.type_y.map(type_weight)            \n",
    "            #df['wgt'] = 1 + 3*(df.ts_x - 1659304800)/(1662328791-1659304800)\n",
    "            \n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            \n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        print()\n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<40].drop('n',axis=1)\n",
    "    # SAVE PART TO DISK\n",
    "    df = tmp.to_pandas().groupby('aid_x').aid_y.apply(list)\n",
    "    with open(f'../../data/covisit_matrices/top_40_aids_v{VER}_{PART}.pkl', 'wb') as f:\n",
    "        pickle.dump(df.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d686d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494762,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12380d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aid_x\n",
       "0     [1036847, 764374, 1470115, 1748507, 49357, 730...\n",
       "2            [881881, 258090, 929227, 1101201, 1581568]\n",
       "3     [1180285, 170046, 1717856, 570922, 1771163, 15...\n",
       "4                                             [1224540]\n",
       "18                    [1290432, 1437333, 336387, 76310]\n",
       "Name: aid_y, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
