{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a450860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import cudf, glob, gc, pickle\n",
    "\n",
    "VER = 162\n",
    "POSTFIX = '_LB'\n",
    "\n",
    "DAY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f71e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('../../data/infer_data/test_parquet/*')\n",
    "len( files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e63fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd95cd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14199779</td>\n",
       "      <td>1747653</td>\n",
       "      <td>1662205325650</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14199780</td>\n",
       "      <td>295604</td>\n",
       "      <td>1662205326327</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14199781</td>\n",
       "      <td>404474</td>\n",
       "      <td>1662205326879</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14199781</td>\n",
       "      <td>939160</td>\n",
       "      <td>1662205330528</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14199782</td>\n",
       "      <td>1477301</td>\n",
       "      <td>1662205327444</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid             ts    type\n",
       "0  14199779  1747653  1662205325650  clicks\n",
       "1  14199780   295604  1662205326327  clicks\n",
       "2  14199781   404474  1662205326879  clicks\n",
       "3  14199781   939160  1662205330528  clicks\n",
       "4  14199782  1477301  1662205327444  clicks"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80ff18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_map = {'clicks':0, 'carts':1, 'orders':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eadb35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/raid/Kaggle/otto/parquet/test_parquet/001300000_001400000.parquet',\n",
       " '/raid/Kaggle/otto/parquet/test_parquet/000800000_000900000.parquet',\n",
       " '/raid/Kaggle/otto/parquet/test_parquet/001500000_001600000.parquet',\n",
       " '/raid/Kaggle/otto/parquet/test_parquet/000000000_000100000.parquet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a4ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type_weight = {0:0, 1:1, 2:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cd3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MN = 1661119200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be254ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### PART 1\n",
      "Processing 17 files...\n",
      "0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , \n",
      "CPU times: user 9.31 s, sys: 2.04 s, total: 11.4 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PIECES = 1\n",
    "SIZE = 1.86e6/PIECES\n",
    "\n",
    "# COMPUTE IN PARTS FOR MEMORY MANGEMENT\n",
    "for PART in range(PIECES):\n",
    "    print()\n",
    "    print('### PART',PART+1)\n",
    "    \n",
    "    # MERGE IS FASTEST PROCESSING CHUNKS WITHIN CHUNKS\n",
    "    # => OUTER CHUNKS\n",
    "    for a,b in [(0,17)]: #,(20,40),(40,60),(60,80),(80,100),(100,120)]:\n",
    "        print(f'Processing {b-a} files...')\n",
    "        \n",
    "        # => INNER CHUNKS\n",
    "        for k in range(a,b):\n",
    "            # READ FILE\n",
    "            df = cudf.read_parquet(files[k])\n",
    "            df.ts = (df.ts//1000).astype('int32')\n",
    "            df['type'] = df['type'].map(type_map)\n",
    "            \n",
    "            #df = df.loc[df.ts>1662328791 - 60*60*24*28]\n",
    "            #df = df.loc[( df.ts >= MN + 60*60*24*DAY )] # START ON DAY OF WEEK \n",
    "            #if len(df)==0: continue\n",
    "                \n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "\n",
    "            # CREATE PAIRS\n",
    "            df = df.merge(df.loc[df['type'].isin([1,2])],on='session')\n",
    "            df = df.loc[ ((df.ts_y - df.ts_x)> 0) ] #& ( df.ts_x < MN + 60*60*24*(DAY+1) ) ] \n",
    "            # MEMORY MANAGEMENT COMPUTE IN PARTS\n",
    "            df = df.loc[(df.aid_x >= PART*SIZE)&(df.aid_x < (PART+1)*SIZE)]\n",
    "            # ASSIGN WEIGHTS\n",
    "            df = df[['session', 'aid_x', 'aid_y','ts_y','ts_x']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            w = (1/2)**((df.ts_y - df.ts_x)/60/60/6) # 6 HOUR HALF LIFE\n",
    "            df['wgt'] = w #df.type_y.map(type_weight)*w\n",
    "            \n",
    "            df = df[['aid_x','aid_y','wgt']]\n",
    "\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "            # COMBINE INNER CHUNKS\n",
    "            if k==a: tmp2 = df\n",
    "            else: tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k,', ',end='')\n",
    "        print()\n",
    "        # COMBINE OUTER CHUNKS\n",
    "        if a==0: tmp = tmp2\n",
    "        else: tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "    # CONVERT MATRIX TO DICTIONARY\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "    # SAVE TOP 40\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n<40].drop('n',axis=1)\n",
    "    # SAVE PART TO DISK\n",
    "    df = tmp.to_pandas().groupby('aid_x').aid_y.apply(list)\n",
    "    with open(f'../../data/covisit_matrices/top_40_aids_v{VER}_d{DAY}_{PART}{POSTFIX}.pkl', 'wb') as f:\n",
    "        pickle.dump(df.to_dict(), f)\n",
    "        \n",
    "    ## SAVE PART TO DISK\n",
    "    #df = tmp.to_pandas().groupby('aid_x').wgt.apply(list)\n",
    "    #with open(f'top_40_aids_v{VER}_{PART}_w.pkl', 'wb') as f:\n",
    "    #    pickle.dump(df.to_dict(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
